# 内存管理策略

# 8.1 背景
  
### 8.1.1 基本硬件
  CPU可以直接访问的只有内存和处理器内置的寄存器。机器指令可以通过内存地址作为参数，但是不能通过磁盘地址作为参数。因此，执行指令和指令使用的数据，应该先处于可以直接访问的存储设备上。
  
  CPU对于寄存器的访问可以在一个CPU周期内完成多次，但是对于内存，往往需要多个CPU周期才能完成。由于内存访问的频繁，这消耗了大量CPU资源。补救措施是在CPU和内存之间，增减缓存（cache）。
  
  为了保证访问的正确性，首先需要保证每个进程都有一个独立的内存空间。单独的进程内存空间可以保护进程互相不受影响。为了分开内存空间，我们需要确定一个进程可以访问的合法地址的范围，并且确保进程只能访问这些合法地址。
  
  通过两个寄存器 **基地址寄存器** 和 **界限地址寄存器** 可以指定一个内存范围。基地址寄存器表示起始地址，界地址寄存器指定了范围的大小。
  只有操作系统可以通过特殊的指令才能加载这两个寄存器。由于特权指令只能在内核模式下执行，而只有操作系统才能在内核模式下执行，所以只有操作系统才可以加载这两个寄存器。
  
### 8.1.2 地址绑定
  通常，程序作为二进制的可执行文件存储在磁盘上。为了被CPU执行，程序必须加载到内存上。根据采用的内存管理，进程在执行时可以在磁盘和内存之间移动。在磁盘上等待调入内存的进程形成了输入队列，也就是就绪队列。
  
  程序上的地址通常是用符号引用表示的，编译器通常把这些符号地址绑定到可重定位的地址。每次绑定都是一次地址映射。
  
  绑定可以在任何一步进行：
  * 编译时：如果在编译时就已经知道进程在内存中的地址，就可以生成绝对代码。
  
  * 加载时：绑定在加载时进行。
  
  * 执行时：进程在执行时如果可以从一个内存段转移到另外一个内存段，那么绑定应该延迟到执行时开始。大部分操作系统都采用这种方式。
  
### 8.1.3 逻辑地址和物理地址
  CPU生成的地址是逻辑地址，内存单元看到的地址是物理地址。
  
  从虚拟地址到物理地址的映射是内存管理单元完成的。

### 8.1.4 动态加载
  一个进程的整个程序和数据都应该在内存中才能执行，因此，进程的大小受限于内存的大小。为了获得更好的内存利用率，可以使用 **动态加载**。
  
  * 动态加载：一个程序只有在调用时才会加载。
  
# 8.2 交换
  进程必须在内存中执行，不过，进程可以暂时从内存交换到磁盘，再次执行时再次调用到内存。
  
  Linux，Unix等系统的交换的实现通常是，当内存低于某个阈值，开启交换，当空闲内存增加，禁用交换。
  
# 8.3 连续内存分配
  内存容纳操作系统和用户进程。内存通常分为两个区域，一个用来驻留操作系统，另外一个用于用户进程。操作系统通常分配在低内存，因为中断向量通常分配在低内存。
  
### 8.3.1 内存保护
  通过基地址寄存器和范围寄存器实现。
  
### 8.3.2 内存分配
  最简单的内存分配就是讲内存分为多个固定大小的分区，每个分区可以只包括一个进程。当一个分区空闲，可以从输入队列中选择进程进入。
  
  操作系统中有一个表记录哪些区可用，每个可用区域都作为一个孔。当新进程需要内存时，系统查找足够大的孔，如果孔太大，就分为两半，一块使用，另外一块回收。两个相邻的孔还可以合并为一个大孔。
  
  对于这种分配内存的策略，分配孔的策略有：
  
  * 首次适应：分配首个足够大的孔，查找可以从头开始，也可以从上次首次适应开始。找到足够大的孔就停止。
  
  * 最优适应：分配最小的足够大孔。
  
  * 最差适应；分配最大的孔。
  
# 8.3.3 碎片
  
  * 外部碎片：有些孔不够任何进程分配，永远无法使用。
  
  * 内部碎片：进程得到的内存和实际使用的内存的差。
  
  解决外部碎片的一种方法是 **紧缩**。通过移动孔，进而合并减少外部碎片。但是，紧缩是有要求的，绑定在编译或者加载时进行就不能紧缩，只有运行时进行，才可以紧缩。
  
  另外一种方式是，允许进程的逻辑空间是不连续的，只要有物理内存可用，就允许为进程分配内存。这种方式有两种实现方式
  
  * 分段
  
  * 分页
  
# 8.4 分段
  分段实现把逻辑空间分为了一组段，每个段都有名称和长度，用户可以通过段名和段内偏移来定位一个地址。
  这种实现方式下，逻辑地址的唯一表示是一个二元组<段名，偏移量>。
  
### 8.4.1 分段硬件
  操作系统维护一个段表，段表的每个条目都有段基地址和段界限。
  
  逻辑地址通过段名对段基地址的映射再加上偏移定位一个物理地址，如果这个地址超出范围，就会陷入操作系统。
  
# 8.5 分页
  分段有外部碎片和紧缩的问题，分页解决了这种问题。
  
### 8.5.1 实现
  物理内存被分为固定大小的块，称为帧；逻辑内存划分为同样大小的块，称为页。这样，逻辑地址空间和物理地址空间独立了出来，实现了虚拟内存。
  
  分页硬件实现由CPU分为两个部分，
  
  * 页码：页码作为页表的索引，页表有对应帧在物理内存的基地址。
  
  * 页偏移：页偏移是物理内存中的偏移量。
  
  页的大小由硬件决定，通常为512字节到1G不等，且为2的N次幂。
  
  可以通过 getconf PAGESIZE 来查看本机页大小（4K）。
  
  通过分页不会产生外部碎片，但是会产生内部碎片。每个进程都由操作系统维护一个页表，来实现物理地址的查找。操作系统维护一个帧表，管理实际的物理内存。
  
### 8.5.2 硬件支持
  通常，我们使用TLB（转换表缓冲区）来实现。TLB是关联的高速内存，通过，TLB只包含少量的页表条目，当CPU产生一个逻辑地址，首先在TLB中查找，如果没有找到，也就是TLB未命中，那么就访问页表，然后添加到TLB中。
  
### 8.5.3 保护

  分页环境下的保护是通过每个帧关联的保护位实现的。这些位位于页表中。
  
  用一个位来表示一个页是可读可写还是只读。用另外一个位来表示该页是否在进程的逻辑内存中。
  
### 8.5.4 共享页
  分页的优点就是可以共享公共代码。
  
  如果代码是可重入代码，那么可以共享。所谓可重入代码，就是多个进程的公共抽取的不能自我修改的代码，它在执行期间不会改变。
  
# 8.6 页表结构
  大多数计算机系统支持大逻辑地址，在这种情况下，页表可能非常大。但我们不想在内存中分配过大比例给页表。
  
  一种解决方法就是二层分页算法。将页表再次进行分页。
  
# 8.6.2 哈希页表
  处理大于32位地址空间的常用方法就是哈希页表。将虚拟页码利用哈希函数进行哈希，得到一个哈希值。每个哈希值对应一个链表。查找页时，页码首先和链表第一个元素匹配，如果匹配，查找到物理地址，否则，查找链表的下一元素。
  
# 8.6.3 倒置页表
         
     